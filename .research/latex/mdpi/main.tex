%  LaTeX support: latex@mdpi.com
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[journal,article,submit,pdftex,moreauthors]{Definitions/mdpi}

%=================================================================
% MDPI internal commands - do not modify
\firstpage{1}
\makeatletter
\setcounter{page}{\@firstpage}
\makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2026}
\copyrightyear{2026}
%\externaleditor{Firstname Lastname} % More than 1 editor, please add `` and '' before the last editor name
\datereceived{ }
\daterevised{ } % Comment out if no revised date
\dateaccepted{ }
\datepublished{ }
%\datecorrected{} % For corrected papers: "Corrected: XXX" date in the original paper.
%\dateretracted{} % For retracted papers: "Retracted: XXX" date in the original paper.
%\doinum{} % Used for some special journals, like molbank
%\pdfoutput=1 % Uncommented for upload to arXiv.org
%\CorrStatement{yes}  % For updates
%\longauthorlist{yes} % For many authors that exceed the left citation part
%\IsAssociation{yes} % For association journals

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, float, amsmath, amssymb, lineno, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, colortbl, soul, multirow, microtype, tikz, totcount, changepage, attrib, upgreek, array, tabularx, pbox, ragged2e, tocloft, marginnote, marginfix, enotez, amsthm, natbib, hyperref, cleveref, scrextend, url, geometry, newfloat, caption, draftwatermark, seqsplit
% cleveref: load \crefname definitions after \begin{document}

\usepackage{algorithm}
\usepackage{algpseudocode}

%=================================================================
% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{Decision-Theoretic Self-Entailment Gating for Adaptive Chain-of-Thought Inference on GSM8K}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0000-0000-000X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-0000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Firstname Lastname $^{1}$\orcidA{}, Firstname Lastname $^{2}$ and Firstname Lastname $^{2,}$*}

%\longauthorlist{yes}

% MDPI internal command: Authors, for metadata in PDF
\AuthorNames{Firstname Lastname, Firstname Lastname and Firstname Lastname}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
$^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
$^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: e-mail@e-mail.com; Tel.:\ (optional; include country code; if there are multiple corresponding authors, add author initials) +xx-xxxx-xxx-xxxx (F.L.)}

% Current address and/or shared authorship
%\firstnote{Current address: Affiliation.}
% Current address should not be the same as any items in the Affiliation section.

%\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes.

%\simplesumm{} % Simple summary

%\conference{} % An extended version of a conference paper

% Abstract (Do not insert blank lines, i.e. \\)
\abstract{Chain-of-Thought (CoT) prompting can raise reasoning accuracy but often increases token cost and can produce fluent rationales that do not actually support the final answer. Standard self-consistency aggregates sampled CoTs as exchangeable votes, which can amplify plausible-but-unsupported traces. We study a training-free inference procedure that casts CoT use as a sequential decision problem with two metacognitive operations: deciding when deliberation is worth the cost, and discounting rationales that fail to increase support for their own answers. Our method, DT-SEACoT, first samples short direct answers to estimate an empirical belief and uncertainty; it gates deliberation based on this uncertainty. When deliberation is triggered, it samples CoT traces and weights each candidate answer by a self-entailment likelihood ratio computed via teacher-forced log-likelihood under the same model, enabling early stopping when the induced posterior becomes concentrated. We instantiate DT-SEACoT with \texttt{google/flan-t5-large} on a $200$-item GSM8K slice ($50$ for tuning, $150$ for final evaluation). The logged run shows strong adaptivity ($94\%$ early stopping; $4.57$ CoT samples on average) but very low accuracy ($5.33\%$, $8/150$). We analyze this negative result, emphasizing failure modes in posterior construction, stopping calibration, and implementation mismatches between the intended Bayesian fusion rule and the executed update.}

% Keywords
\keyword{keyword 1; keyword 2; keyword 3 (List three to ten pertinent keywords specific to the article; yet reasonably common within the subject discipline.)}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data
%\dataset{DOI number or link to the deposited data set if the data set is published separately. If the data set shall be published as a supplement to this paper, this field will be filled by the journal editors. In this case, please submit the data set as a supplement.}
%\datasetlicense{License under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal BioTech, Fishes, Neuroimaging and Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Encyclopedia
%\encyclopediadef{For entry manuscripts only: please provide a brief overview of the entry title instead of an abstract.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Different journals have different requirements. Please check the specific journal guidelines in the "Instructions for Authors" on the journal's official website.
%\addhighlights{yes}
%\renewcommand{\addhighlights}{%
%
%\noindent The goal is to increase the discoverability and readability of the article via search engines and other scholars. Highlights should not be a copy of the abstract, but a simple text allowing the reader to quickly and simplified find out what the article is about and what can be cited from it. Each of these parts should be devoted up to 2~bullet points.\vspace{3pt}\\
%\textbf{What are the main findings?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}\vspace{3pt}
%\textbf{What are the implications of the main findings?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Chain-of-Thought (CoT) prompting has become a standard technique for eliciting multi-step reasoning from large language models (LLMs). By encouraging models to emit intermediate steps, CoT can substantially improve performance on arithmetic and symbolic benchmarks~\cite{wei-2022-chain}, and even a minimal trigger phrase can induce similar behavior in a zero-shot setting~\cite{kojima-2022-large}. However, deploying CoT in real systems raises two intertwined concerns: cost and reliability.

First, deliberation is expensive. Generating multi-step rationales increases tokens, latency, and energy, and the extra computation is not always justified: many inputs are easy enough for a direct answer to succeed. Second, the presence of a rationale does not guarantee correctness. Models can generate explanations that are fluent yet weakly connected to the final answer, or that rationalize an answer after the fact. In such cases, aggregating multiple CoT samples can yield high confidence in an incorrect answer if many samples share correlated errors.

A popular inference-time improvement is self-consistency: sample multiple CoT outputs and pick the plurality final answer. This reduces variance but implicitly treats all sampled traces as equally trustworthy evidence. In settings where unsupported but persuasive traces are common, exchangeable voting can amplify the wrong answer. Meanwhile, a complementary line of work argues that CoT can actively harm performance on tasks where added deliberation introduces noise or distracts from a correct heuristic, paralleling human overthinking~\cite{borges-2023-mind}. This suggests that compute allocation should be selective rather than always-on.

This paper investigates a training-free approach to selective and quality-aware CoT at inference time. We frame inference as a sequential decision and evidence fusion problem. The method begins with a fast System-1 stage that samples short direct answers to form an empirical distribution over candidate numeric outputs. From this distribution we derive uncertainty statistics (maximum probability and entropy) and use a gate to decide whether the question warrants deliberation. If System-1 is stable, the method returns immediately; otherwise it enters System-2 and samples CoT traces. Crucially, System-2 does not treat each trace as an exchangeable vote. Instead, it estimates how much a given rationale supports its own proposed answer using a self-entailment likelihood ratio computed through teacher-forced log-likelihood with the same model. Conceptually, this operationalizes a coherence check: conditioning on the rationale should not decrease, and ideally should increase, the model's probability of the proposed answer. The method further supports early stopping when the posterior induced by accumulated evidence becomes sufficiently concentrated.

Our motivation is aligned with calls for Bayesian meta-reasoning as a unifying perspective on robust, generalizable LLM reasoning~\cite{arves-2024-position} and with recent interest in controlling inference-time ``thinking speed''~\cite{goren-2024-controlling}. At the same time, we impose strict constraints: no fine-tuning, no additional models, and no external verifiers. This setting is attractive for broad applicability but leaves little room to correct systematic model errors.

We implement DT-SEACoT in a small, reproducible codebase and evaluate it on GSM8K, a grade-school math benchmark where CoT often helps but is costly~\cite{wei-2022-chain}. The experimental design includes hyperparameter tuning on a held-out slice with Optuna and final reporting on a separate slice. The available run demonstrates that the method does allocate compute adaptively, frequently stopping after only a few CoT samples. However, the run also yields very low absolute accuracy. Rather than treating this as a mere failure, we present it as an academically useful negative result: it highlights how training-free posterior construction and stopping rules can be severely miscalibrated, and how small implementation choices (for example, how answer strings are represented for likelihood scoring) can dominate outcomes.

Contributions:
\begin{itemize}
\item \textbf{Adaptive training-free CoT inference.} We specify a training-free adaptive CoT inference procedure that combines uncertainty-based gating with a self-entailment likelihood ratio computed via teacher-forced scoring in the same LLM\@.
\item \textbf{Reproducible GSM8K instantiation.} We document an end-to-end instantiation on GSM8K with \texttt{google/flan-t5-large}, including prompts, parsing rules, and an explicit early stopping criterion.
\item \textbf{Negative result and analysis.} We report logged results from the provided run and analyze why strong adaptivity can coincide with poor task accuracy, emphasizing mismatches between the intended and implemented fusion rules and the need for calibrated sequential stopping.
\end{itemize}

Looking forward, our findings suggest several directions: integrating absolute answer likelihood and System-1 priors into evidence fusion (as intended by the original design), improving answer string handling for scoring stability, and adding calibration diagnostics so that early stopping thresholds are meaningful rather than arbitrary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}

\subsection{Chain-of-Thought prompting and zero-shot reasoning}
CoT prompting showed that intermediate reasoning steps can unlock strong performance gains on arithmetic reasoning, including GSM8K, especially in large models~\cite{wei-2022-chain}. Zero-shot-CoT demonstrated that even without demonstrations, a short trigger phrase can elicit step-by-step reasoning behavior~\cite{kojima-2022-large}. Our work keeps the same inference-only spirit but addresses a different question: given that CoT is available, how should a system decide when to use it and how should it aggregate multiple traces?

\subsection{When ``thinking'' hurts: overthinking and compute allocation}
Prior evidence shows that CoT can reduce performance on problems where deliberation introduces noise, echoing human overthinking~\cite{borges-2023-mind}. This observation motivates fast-to-slow patterns where a cheap initial policy is used unless uncertainty is high. DT-SEACoT instantiates this intuition using an empirical uncertainty estimate derived from multiple short direct samples. In contrast to approaches that always generate a rationale, our gate explicitly permits skipping CoT.

\subsection{Meta-reasoning perspectives on LLM inference}
A broader position advocates Bayesian meta-reasoning as a lens for robust and generalizable reasoning, emphasizing uncertainty and value of computation~\cite{arves-2024-position}. DT-SEACoT operationalizes a lightweight version of this idea at inference time: it maintains a belief over candidate answers, sequentially accumulates evidence, and provides an early stopping rule based on posterior concentration. Our contribution is not a new learned model, but rather a training-free procedure that can be layered on top of an existing LLM\@.

\subsection{Controlling inference-time ``thinking speed''}
Work on controlling thinking speed argues that inference-time control of computation is important for practical deployment~\cite{goren-2024-controlling}. DT-SEACoT differs in three ways: it is training-free, uses a single fixed model for both generation and scoring, and grounds its adaptivity in a sequential evidence process rather than a purely prompt-level or length-level knob.

\subsection{Prompt construction and evidence aggregation beyond exchangeable voting}
Automatic prompt selection and construction can improve the raw quality of CoT generations~\cite{maltese-2023-automatic}. This direction is complementary to ours. Even with a strong prompt, aggregation remains non-trivial: sampled traces can still contain correlated errors or unsupported conclusions. DT-SEACoT focuses on inference control and evidence weighting given fixed prompts, rather than searching for new prompts.

The defining contrast with standard self-consistency is that DT-SEACoT does not treat sampled rationales as equally reliable votes. It uses a self-entailment likelihood ratio to discount traces whose rationales do not increase support for their own answers. Unlike verifier-based approaches (not considered here), this signal is derived solely from the base model via teacher-forced likelihoods, preserving the training-free and single-model constraint.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}

This section introduces the formal objects required to describe adaptive CoT inference and the specific GSM8K evaluation protocol used in our experiments.

\subsection{Problem setting and notation}
Let $q$ denote a natural-language math word problem. A language model with parameters $\theta$ defines a conditional distribution over text completions. We focus on numeric answers $y$. In practice the model produces a completion $t$ that may contain both a rationale and a final numeric answer; an answer extractor maps $t$ to a parsed numeric prediction $\hat{y}$. The dataset provides a ground-truth numeric answer $a$ extracted from the canonical GSM8K answer format \texttt{\#\#\#\# number}. A prediction is marked correct when the absolute difference $|\hat{y} - a|$ is less than $10^{-6}$.

\subsection{Direct vs.~rationale-conditioned answer support}
DT-SEACoT distinguishes two conditional answer supports. The direct support is $p_{\theta}(y \mid q)$, approximated by prompting the model to output only the final number. The rationale-conditioned support is $p_{\theta}(y \mid q, r)$, where $r$ is a generated rationale text (in our implementation, the full CoT completion text). The core idea is to use the model's own conditional probabilities as a training-free consistency check.

\subsection{Teacher-forced log-likelihood as a scoring primitive}
To obtain numeric scores for candidate answers without additional models, we use teacher forcing to compute the log-likelihood of a target completion string given a prompt. Concretely, for a prompt $s$ and target completion string $u$, we compute $\log p_{\theta}(u \mid s)$ by running the seq2seq model with $u$ as the decoder labels and summing token log-probabilities (equivalently, negative token-level cross-entropy). This mechanism is implemented in the provided codebase for \texttt{google/flan-t5-large}.

\subsection{Self-entailment likelihood ratio}
For a given candidate answer $y$ and rationale $r$, we define the self-entailment likelihood ratio as
\[
\Delta \mathrm{LL}(y, r) = \log p_{\theta}(y \mid q, r) - \log p_{\theta}(y \mid q).
\]
In our implementation, $\log p_{\theta}(y \mid q)$ is approximated by teacher forcing the answer string under the direct prompt, and $\log p_{\theta}(y \mid q, r)$ is approximated by teacher forcing the same answer string under a prompt that includes the rationale. Intuitively, if a rationale is internally coherent with its conclusion, conditioning on it should not decrease support for that conclusion.

\subsection{Uncertainty from sampled direct answers}
To decide whether to deliberate, System-1 samples $N_{0}$ short direct answers and forms an empirical distribution $p_{0}(y)$ based on counts over extracted numeric answers. Two scalar summaries used by the gate are (i) the maximum probability $\max_{y} p_{0}(y)$ and (ii) the entropy $H(p_{0}) = -\sum_{y} p_{0}(y) \log(p_{0}(y) + 10^{-10})$. These measures are simple, training-free proxies for uncertainty and disagreement.

\subsection{Sequential evidence accumulation and early stopping}
Adaptive CoT can be interpreted as sequentially collecting evidence about $y$ until it is no longer worth paying for more samples. While the motivating design for DT-SEACoT is inspired by sequential testing ideas, the logged implementation uses a pragmatic rule: it maintains unnormalized answer weights derived from accumulated evidence and converts them to a normalized posterior over currently observed answers; sampling stops when the highest posterior mass exceeds a fixed threshold. This background framing clarifies both the intended behavior (selective compute) and the main risk (miscalibrated posteriors).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}

We describe DT-SEACoT as implemented in the provided codebase, emphasizing the exact prompts, evidence calculations, aggregation rule, and early stopping mechanism. The method operates in two stages.

\subsection{System-1: fast direct-answer sampling and gating}
Given a question $q$, DT-SEACoT builds a direct prompt that requests only the final numeric answer:
\begin{quote}
\texttt{Solve this math problem and give only the final numeric answer. Question: <q>. The answer is:}
\end{quote}
It then samples $n_{0}$ independent completions at temperature \texttt{direct\_temperature}, each capped by \texttt{direct\_max\_tokens}. Each completion is parsed into a float using a pattern-based extractor that recognizes formats such as \texttt{\#\#\#\# number}, \texttt{the answer is number}, or \texttt{= number} at the end of the string, with a fallback that selects the last number appearing in the text. From the multiset of parsed answers, it computes \texttt{max\_prob} and \texttt{entropy} of the empirical distribution.

The gating decision is deterministic: deliberation (System-2) is triggered when \texttt{max\_prob} is below \texttt{gate\_confidence\_threshold} or \texttt{entropy} is above \texttt{gate\_entropy\_threshold}. If the gate does not deliberate and at least one answer was parsed, the method returns the most frequent parsed direct answer. If no valid direct answer is parsed, the method proceeds to deliberation.

\subsection{System-2: adaptive CoT sampling with self-entailment weighting}
When System-2 is triggered, DT-SEACoT uses a CoT prompt that requests step-by-step reasoning and asks for the final numeric answer after \texttt{\#\#\#\#}:
\begin{quote}
\texttt{Solve this math problem step by step. Show your work and put your final numeric answer after \#\#\#\#. Question: <q>. Let's solve this step by step:}
\end{quote}
It generates up to $K_{\max}$ samples at temperature \texttt{cot\_temperature} with cap \texttt{cot\_max\_tokens}. For each generated completion $t$, it parses a numeric answer $y$. If parsing fails, the sample is discarded.

If \texttt{use\_self\_entailment} is enabled, DT-SEACoT computes a self-entailment score for this sample using teacher forcing in the same model. Let \texttt{answer\_str} be the string form of the parsed float, \texttt{answer\_str = str(y) }. It computes:
\begin{enumerate}
\item $\ell\ell_{\text{direct}} = \log p_{\theta}(\texttt{answer\_str} \mid \texttt{direct\_prompt})$
\item $\ell\ell_{\text{with\_rationale}} = \log p_{\theta}(\texttt{answer\_str} \mid \texttt{r2a\_prompt})$
\end{enumerate}
where \texttt{r2a\_prompt} has the form:
\begin{quote}
\texttt{Given the reasoning below, what is the final numeric answer? Question: <q>. Reasoning: <t>. Therefore, the answer is:}
\end{quote}
The evidence weight for the sample is $\Delta \ell\ell = \ell\ell_{\text{with\_rationale}} - \ell\ell_{\text{direct}}$. If \texttt{use\_self\_entailment} is disabled, \texttt{evidence\_weight} is set to $0.0$, yielding a uniform-weight aggregation variant.

\subsection{Answer-level evidence fusion}
The method maintains a dictionary mapping each observed answer value $y$ to a log-weight. For the first observation of $y$, it sets \texttt{log\_weight[$y$] } $\leftarrow$ \texttt{evidence\_weight}. For subsequent observations of the same $y$, it updates \texttt{log\_weight[$y$] } using \texttt{logaddexp(old, evidence\_weight)}. This corresponds to summing unnormalized evidence contributions in the probability domain while maintaining numerical stability.

\subsection{Early stopping}
If \texttt{early\_stop\_enabled} is true, DT-SEACoT begins checking for early stopping after at least three CoT samples have been generated. It converts the current log-weights into a normalized posterior over the set of observed candidate answers by exponentiating after subtracting the maximum log-weight and normalizing. If the maximum posterior probability exceeds \texttt{early\_stop\_posterior\_threshold}, sampling halts and the current top answer is returned.

\subsection{Procedure summary}
\begin{algorithm}[H]
\caption{DT-SEACoT inference (as implemented)}
\begin{algorithmic}
\State Build \texttt{direct\_prompt} from question $q$%
\State Sample $n_{0}$ direct completions; parse numeric answers into multiset $\mathcal{Y}_{0}$%
\State Form empirical distribution $p_{0}$ over values in $\mathcal{Y}_{0}$; compute \texttt{max\_prob} and \texttt{entropy}%
\If{$\mathcal{Y}_{0} \neq \emptyset$ \textbf{and} \texttt{max\_prob} $\ge$ \texttt{gate\_confidence\_threshold} \textbf{and} \texttt{entropy} $\le$ \texttt{gate\_entropy\_threshold}}
  \State \Return most frequent $y \in \mathcal{Y}_{0}$%
\EndIf%
\State Initialize map $w(y) \leftarrow -\infty$ for all observed $y$%
\For{$k = 1$ to $K_{\max}$}
  \State Sample CoT completion $t$; parse answer $y$; \textbf{continue} if parsing fails%
  \If{\texttt{use\_self\_entailment}}
    \State Compute $\ell\ell_{\text{direct}} \leftarrow \log p_{\theta}(\texttt{str}(y) \mid \texttt{direct\_prompt})$%
    \State Compute $\ell\ell_{\text{with\_rationale}} \leftarrow \log p_{\theta}(\texttt{str}(y) \mid \texttt{r2a\_prompt}(q,t))$%
    \State $e \leftarrow \ell\ell_{\text{with\_rationale}} - \ell\ell_{\text{direct}}$%
  \Else%
    \State $e \leftarrow 0$%
  \EndIf%
  \State $w(y) \leftarrow \log\big(\exp(w(y)) + \exp(e)\big)$ \Comment{\texttt{logaddexp}}
  \If{\texttt{early\_stop\_enabled} \textbf{and} $k \ge 3$}
    \State Normalize $w$ over observed answers to posterior $\pi$%
    \If{$\max_{y} \pi(y) >$ \texttt{early\_stop\_posterior\_threshold}}
      \State \Return $\arg\max_{y} \pi(y)$%
    \EndIf%
  \EndIf%
\EndFor%
\State \Return $\arg\max_{y} \pi(y)$ over observed answers%
\end{algorithmic}
\end{algorithm}

\subsection{Implementation note relative to the motivating design}
The conceptual design motivating DT-SEACoT includes combining System-1 priors and absolute answer likelihood terms with the self-entailment ratio. The logged implementation uses $\Delta \ell\ell$ as the only evidence term and does not explicitly incorporate System-1 priors into System-2 weights. This difference matters because $\Delta \ell\ell$ captures a relative change in support under conditioning, but does not, by itself, ensure that an answer is plausible under the direct prompt.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Setup}

We evaluate DT-SEACoT on GSM8K using a fixed pretrained model, with a protocol that separates hyperparameter tuning from final evaluation.

\subsection{Dataset construction and splits}
The pipeline loads the GSM8K dataset (\texttt{gsm8k}, configuration \texttt{main}) and uses the test split. It selects up to \texttt{max\_samples} $= 200$ examples, shuffles them with a fixed seed $42$, and discards any examples whose gold answer cannot be parsed from the dataset-provided answer string. Gold answers are extracted using the canonical GSM8K pattern \texttt{\#\#\#\# number} and converted to floats. The resulting $200$ examples are split into $50$ validation examples (for hyperparameter tuning) and $150$ test examples (for final evaluation).

\subsection{Model and inference constraints}
All runs use \texttt{google/flan-t5-large} as a single sequence-to-sequence model with no fine-tuning. The same model is used for (i) generation in System-1 and System-2 and (ii) teacher-forced log-likelihood computations for self-entailment scoring. The configuration supports CUDA execution with bfloat16 weights.

\subsection{Methods under study}
The experimental design includes two methods:
\begin{enumerate}
\item DT-SEACoT (proposed): direct-answer sampling, uncertainty-based gating, CoT sampling, self-entailment weighting, and posterior-threshold early stopping.
\item Fixed-$K$ CoT self-consistency (baseline): sample $k$ CoT completions and return the plurality-vote numeric answer.
\end{enumerate}
While both implementations are present in the code, the metrics payload available for this paper includes only the proposed DT-SEACoT run, so our Results section reports only that method.

\subsection{Prompts and answer extraction}
Direct prompts explicitly request only the final numeric answer and end with \texttt{The answer is:}. CoT prompts explicitly request that the final numeric answer appears after \texttt{\#\#\#\#}. Model outputs are parsed into floats using several patterns (including the GSM8K \texttt{\#\#\#\#} pattern and a last-number fallback). Correctness is computed using absolute error less than $10^{-6}$.

\subsection{Hyperparameter tuning}
The configuration enables Optuna with $20$ trials for both DT-SEACoT and the baseline. For DT-SEACoT, the search space includes \texttt{gate\_confidence\_threshold}, \texttt{gate\_entropy\_threshold}, \texttt{early\_stop\_posterior\_threshold}, and direct and CoT sampling temperatures. For the baseline, the search space includes the CoT sampling temperature. The evaluation payload does not include Optuna trial histories; only the final summary metrics for the DT-SEACoT run are available.

\subsection{Efficiency measurement}
The run logs average counts of direct samples and CoT samples used per question. It also logs \texttt{avg\_tokens\_per\_question} computed as $(\texttt{avg\_direct\_samples} \times \texttt{direct\_max\_tokens}) + (\texttt{avg\_cot\_samples} \times \texttt{cot\_max\_tokens})$. This quantity is an upper-bound-style estimate based on configured maximum new tokens per generation, not a tokenizer-counted sum of actual generated tokens, and it does not include teacher-forced scoring costs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

Only one run is available in the provided metrics payload: \texttt{proposed-flan-t5-large-gsm8k} (DT-SEACoT). No baseline self-consistency metrics are included, so we report absolute performance and internal behavior diagnostics for DT-SEACoT without claiming improvement over alternatives.

\subsection{Overall accuracy}
On the GSM8K test split of $150$ examples, DT-SEACoT achieves accuracy $0.0533$, corresponding to $8$ correct answers out of $150$. This indicates that the method, as configured and implemented in the available run, is not effective for GSM8K problem solving in absolute terms.

\subsection{Adaptive compute behavior}
Despite poor accuracy, the logged statistics show that DT-SEACoT does allocate computation adaptively:
\begin{itemize}
\item System-1 direct sampling: \texttt{avg\_direct\_samples} $= 5.0$, matching the configured sample count.
\item Gating: \texttt{skip\_rate} $= 0.0333$, implying that about $3.3\%$ of items exit after System-1 and about $96.7\%$ trigger System-2 deliberation.
\item System-2 usage: \texttt{avg\_cot\_samples} $= 4.5667$, substantially below the configured maximum \texttt{k\_max\_cot\_samples} $= 16$.
\item Early stopping: \texttt{early\_stop\_rate} $= 0.94$, meaning early stopping triggers for most deliberative items.
\item Total samples: \texttt{total\_samples\_per\_question} $= 9.5667$ (direct plus CoT), reflecting the combination of fixed System-1 sampling and adaptive System-2 sampling.
\end{itemize}

\subsection{Token-cost proxy and measurement limitations}
The run reports \texttt{avg\_tokens\_per\_question} $= 2073.6$. In the code, this quantity is computed from average sample counts multiplied by maximum new-token budgets per generation, rather than counting realized generated tokens with the tokenizer. Moreover, it excludes the additional teacher-forced likelihood computations used for self-entailment scoring. As a result, the logged token number should be interpreted only as a coarse proxy for compute, not as a precise measure of inference cost.

\subsection{Summary figure}
\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{images/metrics_summary_proposed-flan-t5-large-gsm8k.pdf}
\caption{Summary metrics for DT-SEACoT on GSM8K for the run proposed-flan-t5-large-gsm8k; higher values indicate better performance for accuracy, while lower values indicate better performance for compute-related quantities (tokens and sample counts).}
\label{fig:proposed-metrics-summary}
\end{figure}

\subsection{Why strong adaptivity can coexist with poor accuracy}
The combination of $94\%$ early stopping and $5.33\%$ accuracy suggests that the internal posterior used to stop is severely misaligned with correctness: the method becomes confident quickly but is often wrong. The provided analysis points to two plausible contributors grounded in the implementation:
\begin{enumerate}
\item Evidence term mismatch: the intended DT-SEACoT design includes combining a System-1 prior and an absolute direct answer likelihood term with the self-entailment ratio. The implementation uses only the ratio $\Delta \ell\ell$, which measures relative change in support and does not ensure absolute plausibility of $y$ under the direct prompt.
\item Answer string representation for scoring: teacher-forced likelihoods are computed on answer strings produced by \texttt{str(y)} where $y$ is a parsed float. This can change formatting relative to what the model would naturally produce~(for example, dropping trailing zeros), injecting noise into likelihood ratios.
\end{enumerate}

\subsection{Limitations of the current empirical evidence}
Because baseline runs are not present, we cannot quantify a Pareto tradeoff relative to fixed-$K$ self-consistency. We also do not have bootstrap confidence intervals, calibration metrics (such as expected calibration error), or ablation results in the provided logs. Consequently, the current evidence supports only a narrow conclusion: the logged DT-SEACoT run exhibits adaptive sampling behavior but fails to achieve meaningful GSM8K accuracy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

We examined DT-SEACoT, a training-free inference procedure intended to make Chain-of-Thought prompting more metacognitively controlled by combining (i) an uncertainty-based gate derived from multiple short direct answers and (ii) self-entailment-weighted evidence aggregation computed through teacher-forced likelihoods in the same model. The broader aim is to improve reliability and efficiency simultaneously by allocating deliberation only when it is valuable and by discounting rationales that do not support their own conclusions.

On a GSM8K slice evaluated with \texttt{google/flan-t5-large} ($50$ items for tuning and $150$ for final evaluation), the available run demonstrates the intended adaptive dynamics: deliberation is triggered for most items, but System-2 typically terminates early ($94\%$ early-stop rate) after an average of $4.57$ CoT samples. However, the run achieves only $5.33\%$ accuracy ($8/150$), indicating a severe failure of the overall inference procedure in this configuration.

This negative result is still informative. It highlights that training-free posterior construction from self-entailment signals can be miscalibrated and can drive confidently wrong early stopping. It also underscores the importance of aligning the implementation with the intended decision-theoretic update: incorporating System-1 priors and absolute answer likelihood terms, auditing answer-string formatting for teacher-forced scoring stability, and adding calibration diagnostics so that posterior thresholds correspond to meaningful error guarantees. These directions are necessary steps toward principled, training-free metacognitive control of CoT inference.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used: ``Conceptualization, X.X. and Y.Y.; methodology, X.X.; software, X.X.; validation, X.X., Y.Y. and Z.Z.; formal analysis, X.X.; investigation, X.X.; resources, X.X.; data curation, X.X.; writing---original draft preparation, X.X.; writing---review and editing, X.X.; visualization, X.X.; supervision, X.X.; project administration, X.X.; funding acquisition, Y.Y. All authors have read and agreed to the published version of the manuscript.'', please turn to the  \href{http://img.mdpi.org/data/contributor-role-instruction.pdf}{CRediT taxonomy} for the term explanation. Authorship must be limited to those who have contributed substantially to the work~reported.}

\funding{This research received no external funding.}

\dataavailability{All resources used in this study are openly available at }

\acknowledgments{In this study, we automatically carried out a series of research processes—from hypothesis formulation to paper writing—using generative AI.}

\conflictsofinterest{The authors declare no conflicts of interest.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\isPreprints{}{% This command is only used for ``preprints''.
\begin{adjustwidth}{-\extralength}{0cm}
%} % If the paper is ``preprints'', please uncomment this parenthesis.
%\printendnotes[custom] % Un-comment to print a list of endnotes

\bibliographystyle{plainnat}
\bibliography{references}

\PublishersNote{}
%\isPreprints{}{% This command is only used for ``preprints''.
\end{adjustwidth}
%} % If the paper is ``preprints'', please uncomment this parenthesis.
\end{document}
